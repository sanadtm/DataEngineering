# -*- coding: utf-8 -*-
"""testRaceData-sanad.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1aY-0KnDHufyamf0MhiuoUF1vYuV0jAoQ
"""

# Commented out IPython magic to ensure Python compatibility.
# Sanad Thapa - Testing Beautiful Soup
# Data Engineering - Spring 2025
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
# %matplotlib inline
from urllib.request import urlopen
from bs4 import BeautifulSoup

## After importing necessary modules, you should specify the URL containing the dataset and pass it to urlopen() to get the html of the page.

url = "https://www.hubertiming.com/results/2023WyEasterLong"
html = urlopen(url)
soup = BeautifulSoup(html, 'lxml')
type(soup)

# Get the title
title = soup.title
print(title)
# Print out the text
text = soup.get_text()
#print(soup.text)

soup.find_all('a')

all_links = soup.find_all("a")
for link in all_links:
    print(link.get("href"))

rows = soup.find_all('tr')
#print(rows[:10])

for row in rows:
    row_td = row.find_all('td')
print(row_td)
type(row_td)

str_cells = str(row_td)
cleantext = BeautifulSoup(str_cells, "lxml").get_text()
#print(cleantext)
import re

list_rows = []
for row in rows:
    cells = row.find_all('td')
    str_cells = str(cells)
    clean = re.compile('<.*?>')
    clean2 = (re.sub(clean, '',str_cells))
    list_rows.append(clean2)
#print(clean2)
type(clean2)

str
df = pd.DataFrame(list_rows)
df.head(10)

df1 = df[0].str.split(',', expand=True)
df1.head(10)
col_labels = soup.find_all('th')
all_header = []
col_str = str(col_labels)
cleantext2 = BeautifulSoup(col_str, "lxml").get_text()
all_header.append(cleantext2)
#print(all_header)
df2 = pd.DataFrame(all_header)
df2.head()
df3 = df2[0].str.split(',', expand=True)
df3.head()

frames = [df3, df1]

df4 = pd.concat(frames)
df4.head(10)
df5 = df4.rename(columns=df4.iloc[0])
df5.head()

df5.info()
df5.shape
df6 = df5.dropna(axis=0, how='any')
df6.info()
df6.shape

df7 = df6.drop(df6.index[0])
df7.head()

#cleaning the Column Names
df7.columns = df7.columns.str.strip().str.replace(']', '').str.replace('[', '')
print('--------------------')
print(df7.columns.tolist())
print('--------------------')

df7.head()
#print(df7)
time_list = df7['Time'].tolist()
time_mins = []
#print(time_list)

for t in time_list:
    t = t.strip()  # remove any leading/trailing whitespace
    if t.count(':') == 1:
        t = "00:" + t  # add 00 if the hours is missing
    #print(t)
    h, m, s = t.split(':')
    math = (int(h) * 3600 + int(m) * 60 + int(s)) / 60
    time_mins.append(math)

print(time_mins)

# Graphs
df7['Runner_mins'] = time_mins
df7.head()
df7.describe(include=[np.number])
from pylab import rcParams
rcParams['figure.figsize'] = 15, 5
plt.figure(figsize=(15, 5))
sns.set(style="whitegrid")
sns.histplot(df7['Runner_mins'],bins=25,kde=True,stat='density',color='orchid', edgecolor='black')
plt.xlabel("Runner_mins")
plt.ylabel("Chip Time")
plt.show()


#Final Graph
f_fuko = df7.loc[df7['Gender']==' F']['Runner_mins']
m_fuko = df7.loc[df7['Gender']==' M']['Runner_mins']
plt.ylabel("Chip Time")
sns.distplot(f_fuko, hist=True, kde=True, rug=False, hist_kws={'edgecolor':'black'}, label='Female')
sns.distplot(m_fuko, hist=False, kde=True, rug=False, hist_kws={'edgecolor':'black'}, label='Male')
plt.legend()


df7.boxplot(column='Runner_mins', by='Gender')
plt.ylabel('Chip Time')
plt.suptitle("")